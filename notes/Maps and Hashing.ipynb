{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps and Hashing\n",
    "#### Last modified on: July 14, 2019\n",
    "#### Author: Emma Teng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets and Maps\n",
    "\n",
    "- There is no order in Set, while list has order\n",
    "- Map is a set-based data structure, like a dictionary.\n",
    "    \n",
    "    Map = <Key, Value>\n",
    "- A group of keys is a set and keys are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Atlanta\n",
      "Mountain View\n",
      "2\n",
      "Bangalore - India\n",
      "Shanghai - China\n"
     ]
    }
   ],
   "source": [
    "locations = {'North America': {'USA': ['Mountain View']}}\n",
    "locations['North America']['USA'].append('Atlanta')\n",
    "locations['Asia'] = {'India': ['Bangalore']}\n",
    "locations['Asia']['China'] = ['Shanghai']\n",
    "locations['Africa'] = {'Egypt': ['Cairo']}\n",
    "\n",
    "usa_sorted = sorted(locations['North America']['USA'])\n",
    "print (1)\n",
    "for city in usa_sorted:\n",
    "    print (city)\n",
    "\n",
    "asia_cities = []\n",
    "print (2)\n",
    "for countries, cities in locations['Asia'].items():\n",
    "    city_country = cities[0] + \" - \" + countries \n",
    "    asia_cities.append(city_country)\n",
    "asia_sorted = sorted(asia_cities)\n",
    "for city in asia_sorted:\n",
    "    print (city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing\n",
    "\n",
    "Using a hash function allows us to do look ups in constant time.\n",
    "\n",
    "Hash functions:\n",
    "> Value ----Hash Function---> Hash value\n",
    "\n",
    "We give our number to a hash function, which spits out a hash code that turns into the index of an array. Then we can go to our array and get our original value in constant time, since an array look up with an index happens in constant time.\n",
    "\n",
    "For example, we can use the last few digits of a big number and divided it by 10 and use the reminder as the new code,\n",
    "\n",
    "> '12345' -> 45%10 -> 5\n",
    "\n",
    ">'12346' -> 46%10 -> 6\n",
    "\n",
    "> '12347' -> 47%10 -> 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collisions\n",
    "\n",
    "There are times when a hash function will spit out the same hash value for two different inputs, such as '0123456' -> 56%10 = 6 and '6543216' -> 16%10 = 6. This situation is called **collision**.\n",
    "\n",
    "There are two main ways to fix collisions:\n",
    "- change the value in hash function or change our hash function completely, so we can have more than enough slots to store all of our potential values. For example, use 12 instead of 10 as the divider.\n",
    "\n",
    "- we can aslo keep the original hash function but change the structure of our array. For example, instead of storing one hash value in each slot, we can store some type of lists or buckets that contains all values hased at that spot.\n",
    "\n",
    "As a result:\n",
    "- Search time will still be $O(1)$, but it if we change the hash function everytime there is a collision, moving all of our data to a new array requires more space and time complexity.\n",
    "\n",
    "- With the bucket approach, we still need to iterate through some collection,  though a shorter one. Therefore, Hash function have a constant lookup time in the average case, but in the worse case, it will be $O(m)$.\n",
    "\n",
    "Depending on different situations, the solution is chosen from above two methods. We can also design a second hash function inside of the large hash function to split up the large bucket even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Maps\n",
    "\n",
    "> <Key, Value> ---- Hash Function on Key ------> Hash Value: <K, V>\n",
    "\n",
    "`If only we had a function that could give us arrays indices for any key value that we gave it!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hash functions for strings**\n",
    "\n",
    "we can treat `abcd` as $$a * p^0 + b * p^2 + c * p^3 + d * p^4$$\n",
    "We use prime numbers because the provide a good distribution. The most common prime numbers used for this function are 31 and 37."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMap:\n",
    "    \n",
    "    def __init__(self, initial_size=10):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 37\n",
    "        self.num_entries = 0\n",
    "        \n",
    "    def put(self, key, value):\n",
    "        pass\n",
    "    \n",
    "    def get(self, key):\n",
    "        pass\n",
    "    \n",
    "    def get_bucket_index(self, key):\n",
    "        return self.get_hash_code(key)\n",
    "    \n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key:\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            current_coefficient *= self.p\n",
    "\n",
    "        return hash_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5204554\n"
     ]
    }
   ],
   "source": [
    "hash_map = HashMap()\n",
    "\n",
    "bucket_index = hash_map.get_bucket_index(\"abcd\")\n",
    "print(bucket_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compression Function**\n",
    "\n",
    "But the values are huge, we cannot create such large arrays. A very simple, good, and effective compression function can be ` mod len(array)`. The `modulo operator %` returns the remainder of one number when divided by other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMap:\n",
    "    \n",
    "    def __init__(self, initial_size = 10):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 31\n",
    "        self.num_entries = 0\n",
    "        \n",
    "    def put(self, key, value):\n",
    "        pass\n",
    "    \n",
    "    def get(self, key):\n",
    "        pass\n",
    "        \n",
    "    def get_bucket_index(self, key):\n",
    "        bucket_index = self.get_hash_code(keu)\n",
    "        return bucket_index\n",
    "    \n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key: \n",
    "            # 3 compressions\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            hash_code = hash_code % num_buckets                       # compress hash_code\n",
    "            current_coefficient *= self.p\n",
    "            current_coefficient = current_coefficient % num_buckets   # compress coefficient\n",
    "\n",
    "        return hash_code % num_buckets                                # one last compression before returning\n",
    "    \n",
    "    \n",
    "    def size(self):\n",
    "        return self.num_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collision Handling**\n",
    "\n",
    "There are two popular ways in which we handle collisions.\n",
    "\n",
    "1. Closed Addressing or Separate chaining. Closed addressing is a clever technique where we use the same bucket to store multiple objects. The bucket in this case will store a linked list of key-value pairs. Every bucket has it's own separate chain of linked list nodes.\n",
    "2. Open Addressing. we do the following:\n",
    "    * If, after getting the bucket index,  the bucket is empty, we store the object in that particular bucket\n",
    "    \n",
    "    * If the bucket is not empty, we find an alternate bucket index by using another function which modifies the current hash code to give a new code.\n",
    "   \n",
    "Separate chaining is a simple and effective technique to handle collisions and that is what we discuss here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
